{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..'))\n",
    "from AI_scientist.util import sort_two_lists\n",
    "from AI_scientist.pytorch.util_pytorch import to_np_array\n",
    "from AI_scientist.settings.global_param import SCALE_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_object_info(percept_list, chosen_dim = None):\n",
    "    \"\"\"Transform the percepted list of dict structure into a plane dictionary structure.\"\"\"\n",
    "    # Currently it assumes that the objects will not disappear or reappear:\n",
    "    perception_dict_whole = {}\n",
    "    for percept_dict in percept_list:\n",
    "        if len(percept_dict) == 0:\n",
    "            for per_key, per_item in perception_dict_whole.items():\n",
    "                per_item.append([np.NaN] * len(per_item[0]))\n",
    "            perception_dict_whole\n",
    "        for key, info_dict in percept_dict.items():\n",
    "            for subkey, info in info_dict.items():\n",
    "                idx = key + \"_{0}\".format(subkey)\n",
    "                if idx not in perception_dict_whole:\n",
    "                    perception_dict_whole[idx] = []\n",
    "                perception_dict_whole[idx].append(info)\n",
    "    for key in perception_dict_whole:\n",
    "        perception_dict_whole[key] = np.array(perception_dict_whole[key])\n",
    "        if chosen_dim is not None:\n",
    "            chosen_dim = np.array(chosen_dim)\n",
    "            perception_dict_whole[key] = perception_dict_whole[key][:, chosen_dim]\n",
    "    return perception_dict_whole\n",
    "\n",
    "\n",
    "def get_task(\n",
    "    trajectory,\n",
    "    num_examples,\n",
    "    bouncing_list,\n",
    "    obs_array = None,\n",
    "    time_steps = 3,\n",
    "    forward_steps = 1,\n",
    "    is_flatten = True,\n",
    "    output_dims = None,\n",
    "    isTorch = True,\n",
    "    is_cuda = False,\n",
    "    width = None,\n",
    "    test_size = 0.2,\n",
    "    bounce_focus = False,\n",
    "    normalize = True,\n",
    "    translation = None,\n",
    "    ):  \n",
    "    \"\"\"Obtain training and testing data from a trajectory\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    info = {}\n",
    "    others = []\n",
    "    reflect = []\n",
    "    if obs_array is not None:\n",
    "        obs_array = obs_array.squeeze()\n",
    "        obs_array = obs_array\n",
    "        obs_X = []\n",
    "        obs_y = []\n",
    "    \n",
    "    # Configure forward steps:\n",
    "    if not isinstance(forward_steps, list) and not isinstance(forward_steps, tuple):\n",
    "        forward_steps = [forward_steps]\n",
    "    forward_steps = list(forward_steps)\n",
    "    assert min(forward_steps) == 1\n",
    "    max_forward_steps = max(forward_steps)\n",
    "\n",
    "    for i in range(len(trajectory) - time_steps - max_forward_steps + 1):\n",
    "        X.append(trajectory[i: i + time_steps])\n",
    "        y.append(trajectory[i + time_steps + np.array(forward_steps) - 1])\n",
    "        reflect.append(np.any(bouncing_list[i + 1: i + time_steps + max_forward_steps]).astype(int))\n",
    "        if obs_array is not None:\n",
    "            obs_X.append(obs_array[i: i + time_steps])\n",
    "            obs_y.append(obs_array[i + time_steps + np.array(forward_steps) - 1])\n",
    "        if max_forward_steps > 1:\n",
    "            others.append(trajectory[i + time_steps : i + time_steps + max_forward_steps - 1])\n",
    "        else:\n",
    "            others.append([1])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    reflect = np.array(reflect)\n",
    "    others = np.array(others)\n",
    "    if obs_array is not None:\n",
    "        obs_X = np.array(obs_X)\n",
    "        obs_y = np.array(obs_y)\n",
    "\n",
    "    # Delete entries with NaN (indicating new game):\n",
    "    valid_X = ~np.isnan(X.reshape(X.shape[0], -1).sum(1))\n",
    "    valid_y = ~np.isnan(y.reshape(y.shape[0], -1).sum(1))\n",
    "    valid_others = ~np.isnan(others.reshape(others.shape[0], -1).sum(1))\n",
    "    valid = valid_X & valid_y & valid_others\n",
    "    X = X[valid]\n",
    "    y = y[valid]\n",
    "    reflect = reflect[valid]\n",
    "    if obs_array is not None:\n",
    "        obs_X = obs_X[valid]\n",
    "        obs_y = obs_y[valid]\n",
    "\n",
    "    # Emphasizing trajectories with bouncing:\n",
    "    if bounce_focus:\n",
    "        X = X[reflect.astype(bool)]\n",
    "        y = y[reflect.astype(bool)]\n",
    "        if obs_array is not None:\n",
    "            obs_X = obs_X[reflect.astype(bool)]\n",
    "            obs_y = obs_y[reflect.astype(bool)]\n",
    "        reflect = reflect[reflect.astype(bool)]\n",
    "    \n",
    "    if translation is not None:\n",
    "        X[..., 0] = X[..., 0] + translation[0]\n",
    "        y[..., 0] = y[..., 0] + translation[0]\n",
    "        X[..., 1] = X[..., 1] + translation[1]\n",
    "        y[..., 1] = y[..., 1] + translation[1]\n",
    "    if normalize:\n",
    "        # scale the states to between (0,1):\n",
    "        X = X * SCALE_FACTOR\n",
    "        y = y * SCALE_FACTOR\n",
    "\n",
    "    # Randomly select num_examples of examples:\n",
    "    chosen_idx = np.random.choice(range(len(X)), size = num_examples, replace = False)\n",
    "    X = X[chosen_idx]\n",
    "    y = y[chosen_idx]\n",
    "    reflect = reflect[chosen_idx]\n",
    "    if obs_array is not None:\n",
    "        obs_X = obs_X[chosen_idx]\n",
    "        obs_y = obs_y[chosen_idx]\n",
    "        max_value = max(obs_X.max(), obs_y.max())\n",
    "        obs_X = obs_X / max_value\n",
    "        obs_y = obs_y / max_value\n",
    "    \n",
    "    if output_dims is not None:\n",
    "        if not isinstance(output_dims, list) and not isinstance(output_dims, tuple):\n",
    "            output_dims = [output_dims]\n",
    "        output_dims = torch.LongTensor(np.array(output_dims))\n",
    "        if is_cuda:\n",
    "            output_dims = output_dims.cuda()\n",
    "        y = y[..., output_dims]\n",
    "\n",
    "    if is_flatten and obs_array is None:\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "        y = y.reshape(y.shape[0], -1)\n",
    "        others = others.reshape(others.shape[0], -1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, reflected_train, reflected_test = train_test_split(X, y, reflect, test_size = test_size)\n",
    "    if obs_array is not None:\n",
    "        X_train, X_test, y_train, y_test, reflected_train, reflected_test, obs_X_train, obs_X_test, obs_y_train, obs_y_test = train_test_split(X, y, reflect, obs_X, obs_y, test_size = test_size)\n",
    "    input_size = X.shape[1:]\n",
    "    output_size = y.shape[1:]\n",
    "    info[\"input_size\"] = input_size[0] if len(input_size) == 1 else input_size\n",
    "    info[\"output_size\"] = output_size[0] if len(output_size) == 1 else output_size\n",
    "    if isTorch:\n",
    "        X_train = Variable(torch.FloatTensor(X_train), requires_grad = False)\n",
    "        y_train = Variable(torch.FloatTensor(y_train), requires_grad = False)\n",
    "        X_test = Variable(torch.FloatTensor(X_test), requires_grad = False)\n",
    "        y_test = Variable(torch.FloatTensor(y_test), requires_grad = False)\n",
    "        reflected_train = Variable(torch.ByteTensor(reflected_train), requires_grad = False)\n",
    "        reflected_test = Variable(torch.ByteTensor(reflected_test), requires_grad = False)\n",
    "        if obs_array is not None:\n",
    "            obs_X_train = Variable(torch.FloatTensor(obs_X_train), requires_grad = False)\n",
    "            obs_y_train = Variable(torch.FloatTensor(obs_y_train), requires_grad = False)\n",
    "            obs_X_test = Variable(torch.FloatTensor(obs_X_test), requires_grad = False)\n",
    "            obs_y_test = Variable(torch.FloatTensor(obs_y_test), requires_grad = False)\n",
    "        if is_cuda:\n",
    "            X_train = X_train.cuda()\n",
    "            y_train = y_train.cuda()\n",
    "            X_test = X_test.cuda()\n",
    "            y_test = y_test.cuda()\n",
    "            reflected_train = reflected_train.cuda()\n",
    "            reflected_test = reflected_test.cuda()\n",
    "            if obs_array is not None:\n",
    "                obs_X_train = obs_X_train.cuda()\n",
    "                obs_y_train = obs_y_train.cuda()\n",
    "                obs_X_test = obs_X_test.cuda()\n",
    "                obs_y_test = obs_y_test.cuda()\n",
    "    if obs_array is None:\n",
    "        return ((X_train, y_train), (X_test, y_test), (reflected_train, reflected_test)), info\n",
    "    else:\n",
    "        info[\"states\"] = ((X_train, y_train), (X_test, y_test))\n",
    "        return ((obs_X_train, obs_y_train), (obs_X_test, obs_y_test), (reflected_train, reflected_test)), info\n",
    "\n",
    "\n",
    "def get_env_data(\n",
    "    env_name,\n",
    "    data_format = \"states\",\n",
    "    input_dims = 1,\n",
    "    output_dims = None,\n",
    "    ball_idx = 0,\n",
    "    num_examples = 10000,\n",
    "    test_size = 0.2,\n",
    "    is_cuda = False,\n",
    "    isplot = 1,\n",
    "    verbose = True,\n",
    "    **kwargs\n",
    "    ):\n",
    "    if env_name[:9] == \"piecewise\":\n",
    "        env_name_split = env_name.split(\"-\")\n",
    "        input_size = int(env_name_split[1][:-1])\n",
    "        num_pieces = int(env_name_split[2][:-1])\n",
    "        num_boundaries = int(env_name_split[3][:-1])\n",
    "        func_types = []\n",
    "        for letter in env_name_split[4]:\n",
    "            if letter == \"l\":\n",
    "                func_types.append(\"linear\")\n",
    "            elif letter == \"q\":\n",
    "                func_types.append(\"quadratic\")\n",
    "            else:\n",
    "                raise Exception(\"letter {0} is not a valid function type!\".format(letter))\n",
    "        ((X_train, y_train), (X_test, y_test), (reflected_train, reflected_test)), info = \\\n",
    "            get_piecewise_dataset(input_size = input_size, \n",
    "                                  num_pieces = num_pieces,\n",
    "                                  num_boundaries = num_boundaries,\n",
    "                                  func_types = func_types,\n",
    "                                  x_range = kwargs[\"x_range\"] if \"x_range\" in kwargs else (0, 20),\n",
    "                                  num_examples = num_examples,\n",
    "                                  is_cuda = is_cuda,\n",
    "                                  isplot = isplot,\n",
    "                                 )\n",
    "    \n",
    "    else:\n",
    "        from AI_scientist.settings.a2c_env_settings import ENV_SETTINGS_CHOICE\n",
    "        from AI_scientist.variational.envs import make_env\n",
    "        from AI_scientist.util import plot_matrices\n",
    "        import random\n",
    "\n",
    "        # Obtain settings from kwargs:\n",
    "        time_steps = kwargs[\"time_steps\"] if \"time_steps\" in kwargs else 3\n",
    "        forward_steps = kwargs[\"forward_steps\"] if \"forward_steps\" in kwargs else [1]\n",
    "        episode_length = kwargs[\"episode_length\"] if \"episode_length\" in kwargs else 30\n",
    "        is_flatten = kwargs[\"is_flatten\"] if \"is_flatten\" in kwargs else False\n",
    "        bounce_focus = kwargs[\"bounce_focus\"] if \"bounce_focus\" in kwargs else True\n",
    "        normalize = kwargs[\"normalize\"] if \"normalize\" in kwargs else True\n",
    "        translation = kwargs[\"translation\"] if \"translation\" in kwargs else None\n",
    "        render = kwargs[\"render\"] if \"render\" in kwargs else False\n",
    "        env_name_split = env_name.split(\"-\")\n",
    "        if \"nobounce\" in env_name_split:\n",
    "            env_name_core = \"-\".join(env_name_split[:-1])\n",
    "        else:\n",
    "            env_name_core = env_name\n",
    "        env_settings = {key: random.choice(value) if isinstance(value, list) else value for key, value in ENV_SETTINGS_CHOICE[env_name_core].items()}\n",
    "        env_settings[\"info_contents\"] = [\"coordinates\"]\n",
    "        max_distance = env_settings[\"max_distance\"] if \"max_distance\" in env_settings else None\n",
    "        max_range = env_settings[\"max_range\"] if \"max_range\" in env_settings else None\n",
    "        if max_range is not None:\n",
    "            value_min, value_max = max_range\n",
    "        input_dims = env_settings[\"input_dims\"] if \"input_dims\" in env_settings else input_dims\n",
    "\n",
    "        # Reset certain aspects of the environment:\n",
    "        if \"screen_width\" in kwargs:\n",
    "            print(\"corrected screen_width: {0}\".format(kwargs[\"screen_width\"]))\n",
    "            env_settings[\"screen_width\"] = kwargs[\"screen_width\"]\n",
    "        if \"screen_height\" in kwargs:\n",
    "            print(\"corrected screen_height: {0}\".format(kwargs[\"screen_height\"]))\n",
    "            env_settings[\"screen_height\"] = kwargs[\"screen_height\"]\n",
    "        if \"physics\" in kwargs:\n",
    "            print(\"corrected physics: {0}\".format(kwargs[\"physics\"]))\n",
    "            env_settings[\"physics\"] = kwargs[\"physics\"]\n",
    "        if \"boundaries\" in kwargs:\n",
    "            print(\"corrected boundaries: {0}\".format(kwargs[\"boundaries\"]))\n",
    "            env_settings[\"boundaries\"] = kwargs[\"boundaries\"]\n",
    "        if \"ball_vmax\" in kwargs:\n",
    "            print(\"corrected ball_vmax: {0}\".format(kwargs[\"ball_vmax\"]))\n",
    "            env_settings[\"ball_vmax\"] = kwargs[\"ball_vmax\"]\n",
    "        if \"step_dt\" in kwargs:\n",
    "            print(\"corrected step_dt: {0}\".format(kwargs[\"step_dt\"]))\n",
    "            env_settings[\"step_dt\"] = kwargs[\"step_dt\"]\n",
    "        env = make_env(\"Breakout_Custom-v0\", 1, 0, \"\", clip_rewards = False, env_settings = env_settings)()\n",
    "        env.allow_early_resets = True\n",
    "\n",
    "        obs_var = []\n",
    "        info_list = []\n",
    "        bouncing_list = []\n",
    "\n",
    "        k = 0\n",
    "        num_episodes_candidate = max(1, 1.5 * int(num_examples / (episode_length - time_steps - max(forward_steps))))\n",
    "        if bounce_focus:\n",
    "            num_episodes_candidate * 2\n",
    "        while k < num_episodes_candidate:\n",
    "            obs = env.reset()\n",
    "            obs_var_candidate = []\n",
    "            info_list_candidate = []\n",
    "            bouncing_list_candidate = []\n",
    "            ball_x = None\n",
    "            ball_y = None\n",
    "            is_break = False\n",
    "            # Obtain the frames:\n",
    "            for i in range(episode_length):\n",
    "                obs, _, _, info = env.step(1)\n",
    "                obs_var_candidate.append(obs)\n",
    "                coordinates = info[\"coordinates\"]\n",
    "                info_list_candidate.append(coordinates)\n",
    "                bouncing_list_candidate.append(info[\"ball_bouncing_info\"])\n",
    "                if max_distance is not None:\n",
    "                    last_ball_x = ball_x\n",
    "                    last_ball_y = ball_y\n",
    "                    ball_x, ball_y = coordinates[\"ball\"][ball_idx]\n",
    "                    if last_ball_x is not None:\n",
    "                        if abs(ball_x - last_ball_x) > max_distance:\n",
    "                            is_break = True\n",
    "                            if verbose:\n",
    "                                print(\"{0} break for too large velocity.\".format(k))\n",
    "                            break\n",
    "                if max_range is not None:\n",
    "                    ball_x, ball_y = coordinates[\"ball\"][ball_idx]\n",
    "                    if ball_x < value_min or ball_x > value_max or ball_y < value_min or ball_y > value_max:\n",
    "                        is_break = True\n",
    "                        if verbose:\n",
    "                            print(\"{0} break for going outsize the max_range\".format(k))\n",
    "                        break\n",
    "                if render:\n",
    "                    time.sleep(0.1)\n",
    "                    env.render('human')\n",
    "            # Only add the episode if it is does not break:\n",
    "            if not is_break:\n",
    "                obs_var = obs_var + obs_var_candidate\n",
    "                info_list = info_list + info_list_candidate\n",
    "                bouncing_list = bouncing_list + bouncing_list_candidate\n",
    "                obs_var.append({})\n",
    "                info_list.append({})\n",
    "                bouncing_list.append({})\n",
    "                k += 1\n",
    "        if isplot > 0:\n",
    "            plot_matrices(np.array(obs_var[:30]).squeeze())\n",
    "\n",
    "        # Process the info_list into numpy format:\n",
    "        perception_dict = process_object_info(info_list, chosen_dim = input_dims)\n",
    "        bouncing_list = [len(element[ball_idx]) if len(element) > 0 else np.NaN for element in bouncing_list]\n",
    "        if data_format == \"images\":\n",
    "            obs_array = np.array([element if len(element) > 0 else np.full(obs_var[0].shape, np.nan) for element in obs_var])\n",
    "        else:\n",
    "            obs_array = None\n",
    "        trajectory0 = perception_dict[\"ball_{0}\".format(ball_idx)]\n",
    "        width = env_settings[\"screen_width\"] if input_dims == 0 else env_settings[\"screen_height\"]\n",
    "        ((X_train, y_train), (X_test, y_test), (reflected_train, reflected_test)), info = \\\n",
    "            get_task(trajectory0,\n",
    "                     num_examples = num_examples,\n",
    "                     bouncing_list = bouncing_list,\n",
    "                     obs_array = obs_array,\n",
    "                     time_steps = time_steps,\n",
    "                     forward_steps = forward_steps,\n",
    "                     is_flatten = is_flatten,\n",
    "                     output_dims = output_dims,\n",
    "                     is_cuda = is_cuda,\n",
    "                     width = width,\n",
    "                     test_size = test_size,\n",
    "                     bounce_focus = bounce_focus,\n",
    "                     normalize = normalize,\n",
    "                     translation = translation,\n",
    "                    )\n",
    "\n",
    "        if \"nobounce\" in env_name_split:\n",
    "            if obs_array is None:\n",
    "                X_train = X_train[reflected_train.unsqueeze(1) == 0].view(-1, X_train.size(1))\n",
    "                y_train = y_train[reflected_train.unsqueeze(1) == 0].view(-1, y_train.size(1))\n",
    "                X_test = X_test[reflected_test.unsqueeze(1) == 0].view(-1, X_test.size(1))\n",
    "                y_test = y_test[reflected_test.unsqueeze(1) == 0].view(-1, y_test.size(1))\n",
    "            else:\n",
    "                X_train = X_train[reflected_train.view(reflected_train.size(0), 1,1,1) == 0].view(-1, *X_train.size()[1:])\n",
    "                y_train = y_train[reflected_train.view(reflected_train.size(0), 1,1,1) == 0].view(-1, *y_train.size()[1:])\n",
    "                X_test = X_test[reflected_test.view(reflected_test.size(0), 1,1,1) == 0].view(-1, *X_test.size()[1:])\n",
    "                y_test = y_test[reflected_test.view(reflected_test.size(0), 1,1,1) == 0].view(-1, *y_test.size()[1:])\n",
    "            reflected_train = reflected_train[reflected_train == 0]\n",
    "            reflected_test = reflected_test[reflected_test == 0]\n",
    "    return ((X_train, y_train), (X_test, y_test), (reflected_train, reflected_test)), info\n",
    "\n",
    "\n",
    "def get_torch_tasks(\n",
    "    tasks,\n",
    "    task_key,\n",
    "    start_id = 0,\n",
    "    num_tasks = None,\n",
    "    num_forward_steps = None,\n",
    "    is_flatten = True,\n",
    "    is_oracle = False,\n",
    "    is_cuda = False,\n",
    "    ):\n",
    "    tasks_dict = OrderedDict()\n",
    "    for i, task in enumerate(tasks):\n",
    "        if num_tasks is not None and i > num_tasks:\n",
    "            break\n",
    "        ((X_train_numpy, y_train_numpy), (X_test_numpy, y_test_numpy)), z_info = task\n",
    "        X_train = Variable(torch.FloatTensor(X_train_numpy), requires_grad = False)\n",
    "        y_train = Variable(torch.FloatTensor(y_train_numpy), requires_grad = False)\n",
    "        X_test = Variable(torch.FloatTensor(X_test_numpy), requires_grad = False)\n",
    "        y_test = Variable(torch.FloatTensor(y_test_numpy), requires_grad = False)\n",
    "        \n",
    "        if len(y_train.size()) == 3:\n",
    "            if num_forward_steps is not None:\n",
    "                y_train = y_train[:, :num_forward_steps, :]\n",
    "                y_test = y_test[:, :num_forward_steps, :]\n",
    "        \n",
    "            if is_flatten:\n",
    "                X_train = X_train.contiguous().view(X_train.size(0), -1)\n",
    "                y_train = y_train.contiguous().view(y_train.size(0), -1)\n",
    "                X_test = X_test.contiguous().view(X_test.size(0), -1)\n",
    "                y_test = y_test.contiguous().view(y_test.size(0), -1)\n",
    "        if is_oracle and len(X_train.size()) != 4:\n",
    "            z_train = Variable(torch.FloatTensor(np.repeat(np.expand_dims(z_info[\"z\"],0) * SCALE_FACTOR, len(X_train), 0)), requires_grad = False)\n",
    "            z_test = Variable(torch.FloatTensor(np.repeat(np.expand_dims(z_info[\"z\"],0) * SCALE_FACTOR, len(X_test), 0)), requires_grad = False)\n",
    "            X_train = torch.cat([X_train, z_train], 1)\n",
    "            X_test = torch.cat([X_test, z_test], 1)\n",
    "        \n",
    "        if is_cuda:\n",
    "            X_train = X_train.cuda()\n",
    "            y_train = y_train.cuda()\n",
    "            X_test = X_test.cuda()\n",
    "            y_test = y_test.cuda()\n",
    "        tasks_dict[\"{0}_{1}\".format(task_key, i + start_id)] = [[[X_train, y_train], [X_test, y_test]], z_info]\n",
    "    return tasks_dict\n",
    "\n",
    "\n",
    "def get_numpy_tasks(tasks):\n",
    "    tasks_save = []\n",
    "    for task_key, task in tasks.items():\n",
    "        ((X_train, y_train), (X_test, y_test)), z_info = task\n",
    "        tasks_save.append([[[to_np_array(X_train), to_np_array(y_train)], [to_np_array(X_test), to_np_array(y_test)]], z_info])\n",
    "    return tasks_save\n",
    "\n",
    "\n",
    "def sort_datapoints(X, y, score, top = None):\n",
    "    combined_data = torch.cat([X, y], 1)\n",
    "    isTorch = False\n",
    "    if isinstance(score, Variable):\n",
    "        score = score.squeeze().data.numpy()\n",
    "    if isinstance(X, Variable):\n",
    "        isTorch = True\n",
    "    score_sorted, data_sorted = sort_two_lists(score, combined_data.data.numpy(), reverse = True)\n",
    "    data_sorted = np.array(data_sorted)\n",
    "    score_sorted = np.array(score_sorted)\n",
    "    X_sorted, y_sorted = data_sorted[:,:X.size(1)], data_sorted[:,X.size(1):]\n",
    "    if top is not None:\n",
    "        X_sorted = X_sorted[:top]\n",
    "        y_sorted = y_sorted[:top]\n",
    "        score_sorted = score_sorted[:top]\n",
    "    if isTorch:\n",
    "        X_sorted = Variable(torch.FloatTensor(X_sorted)).contiguous().view(-1,X.size(1))\n",
    "        y_sorted = Variable(torch.FloatTensor(y_sorted)).contiguous().view(-1,y.size(1))\n",
    "    return X_sorted, y_sorted, score_sorted\n",
    "\n",
    "\n",
    "def predict_forward(model, X, num_forward_steps = 1):\n",
    "    current_state = X\n",
    "    pred_list = []\n",
    "    for i in range(num_forward_steps):\n",
    "        pred = model(current_state)\n",
    "        pred_list.append(pred)\n",
    "        current_state = torch.cat([current_state[:, 2:], pred], 1)\n",
    "    preds = torch.cat(pred_list, 1)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def reshape_time_series(tensor):\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        return tensor.reshape(tensor.shape[0], -1, 2)\n",
    "    else:\n",
    "        return tensor.view(tensor.size(0), -1, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
